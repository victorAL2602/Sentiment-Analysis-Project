{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51031be3-9920-43ae-818e-58d1686201b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin      reviewerName helpful  \\\n",
      "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
      "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
      "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
      "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
      "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  They look good and stick good! I just don't li...        4   \n",
      "1  These stickers work like the review says they ...        5   \n",
      "2  These are awesome and make my phone look so st...        5   \n",
      "3  Item arrived in great time and was in perfect ...        4   \n",
      "4  awesome! stays on, and looks great. can be use...        5   \n",
      "\n",
      "                                     summary  unixReviewTime   reviewTime  \n",
      "0                                 Looks Good      1400630400  05 21, 2014  \n",
      "1                      Really great product.      1389657600  01 14, 2014  \n",
      "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
      "3                                      Cute!      1382313600  10 21, 2013  \n",
      "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load train and test datasets\n",
    "df = pd.read_json(r\"C:\\Users\\victo\\OneDrive\\Desktop\\amazon reviews\\Cell_Phones_and_Accessories_5.json\", lines = True)\n",
    "\n",
    "#check for the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fc0643b-eb02-41fe-9eae-2f8fd9573ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  \\\n",
      "0  They look good and stick good! I just don't li...   \n",
      "1  These stickers work like the review says they ...   \n",
      "2  These are awesome and make my phone look so st...   \n",
      "3  Item arrived in great time and was in perfect ...   \n",
      "4  awesome! stays on, and looks great. can be use...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  look good stick good dont like rounded shape a...  \n",
      "1  stickers work like review says stick great sta...  \n",
      "2  awesome make phone look stylish used one far a...  \n",
      "3  item arrived great time perfect condition howe...  \n",
      "4  awesome stays looks great used multiple apple ...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the set of stopwords in English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Ensure the text is a string\n",
    "    text = str(text)\n",
    "    \n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 3. Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # 4. Join words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the 'reviewText' column\n",
    "df['cleaned_review'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Check the cleaned text\n",
    "print(df[['reviewText', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8e457bc-4999-4482-9a4a-82cf3bd92c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   overall  sentiment\n",
      "0        4        1.0\n",
      "1        5        1.0\n",
      "2        5        1.0\n",
      "3        4        1.0\n",
      "4        5        1.0\n"
     ]
    }
   ],
   "source": [
    "# Function to map ratings to sentiment\n",
    "def map_sentiment(rating):\n",
    "    if rating > 3:\n",
    "        return 1 #positive\n",
    "    elif rating < 3:\n",
    "        return 0 #negative\n",
    "    else:\n",
    "        return None #Neutral\n",
    "\n",
    "# Apply the mapping function to the 'overall' column\n",
    "df['sentiment'] = df['overall'].apply(map_sentiment)\n",
    "\n",
    "# Drop rows with 'None' in the sentiment column (if you want to ignore neutral reviews)\n",
    "df = df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Check the mapping\n",
    "print(df[['overall', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4216ae5e-6a15-4519-84a7-59be06ba944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer (limiting to top 5000 features)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned review text\n",
    "X = tfidf.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Target variable (sentiment)\n",
    "y = df['sentiment']\n",
    "\n",
    "# Check the shape of the feature matrix\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7d001b1-ad69-44b3-b36a-d5514faf529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (138400, 5000), Test size: (34600, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes of the training and testing sets\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e186d4b-4bf2-43b7-8c2b-e7e93dd92396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.59      0.69      4900\n",
      "         1.0       0.94      0.98      0.96     29700\n",
      "\n",
      "    accuracy                           0.92     34600\n",
      "   macro avg       0.88      0.78      0.82     34600\n",
      "weighted avg       0.92      0.92      0.92     34600\n",
      "\n",
      "[[ 2890  2010]\n",
      " [  603 29097]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6240515-1d06-4d35-a86b-aa92184c8f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
